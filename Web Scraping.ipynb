{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a241aeb-906c-435f-a8e0-d9e69ec437a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   NBA Salarios y jugadores Title\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h3>\n",
      "   <b id=\"boldest\">\n",
      "    Lebron James\n",
      "   </b>\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $ 92,000,000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Stephen Curry\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $85,000, 000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Kevin Durant\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $73,200, 000\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n",
      "EL titulo es: <title>NBA Salarios y jugadores Title</title>\n",
      "Los nombres son:  ['Lebron James', ' Stephen Curry', ' Kevin Durant ']\n",
      "<h3><b id=\"boldest\">Lebron James</b></h3>\n",
      "Salario de Curry:  Salary: $85,000, 000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lebron James'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "\n",
    "# Define the HTML content as a string instead of using %%html magic\n",
    "html = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>NBA Salarios y jugadores Title</title>\n",
    "</head>\n",
    "<body>\n",
    "<h3><b id='boldest'>Lebron James</b></h3>\n",
    "<p> Salary: $ 92,000,000 </p>\n",
    "<h3> Stephen Curry</h3>\n",
    "<p> Salary: $85,000, 000 </p>\n",
    "<h3> Kevin Durant </h3>\n",
    "<p> Salary: $73,200, 000</p>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "# Now parse the HTML string with BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "Obtener_titulo = soup.title\n",
    "print(\"EL titulo es:\", Obtener_titulo)\n",
    "\n",
    "nombre = []\n",
    "\n",
    "for h3 in soup.find_all(\"h3\"):\n",
    "    if h3.b:\n",
    "        nombre.append(h3.b.text)\n",
    "    else:\n",
    "        nombre.append(h3.text)\n",
    "print(\"Los nombres son: \", nombre)\n",
    "\n",
    "Obtener_titulo=soup.h3\n",
    "print(Obtener_titulo)\n",
    "\n",
    "tag_child =Obtener_titulo.b\n",
    "tag_child\n",
    "\n",
    "Obtener_titulo\n",
    "Obtener_titulo.parent\n",
    "\n",
    "sibling_1=Obtener_titulo.next_sibling\n",
    "sibling_1\n",
    "\n",
    "sibling_2=sibling_1.next_sibling\n",
    "sibling_2\n",
    "\n",
    "# Encontrar el h3 de Stephen Curry\n",
    "curry_h3 = soup.find(\"h3\", string=\" Stephen Curry\")\n",
    "# Obtener el siguiente elemento (espacio en blanco)\n",
    "sibling_1 = curry_h3.next_sibling\n",
    "# Obtener el elemento p que contiene el salario\n",
    "sibling_2 = sibling_1.next_sibling\n",
    "# Imprimir el salario de Curry\n",
    "print(\"Salario de Curry:\", sibling_2.text)\n",
    "\n",
    "tag_child['id']\n",
    "\n",
    "tag_child.attrs\n",
    "\n",
    "tag_child.get('id')\n",
    "\n",
    "tag_string=tag_child.string\n",
    "tag_string\n",
    "\n",
    "type(tag_string)\n",
    "\n",
    "unicode_string = str(tag_string)\n",
    "unicode_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2545829e-57ac-44d7-9b51-a21657acf7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "row 0 is <tr>\n",
      "<td id=\"flight\">Flight No</td>\n",
      "<td>Launch site</td>\n",
      "<td>Payload mass</td>\n",
      "</tr>\n",
      "row 1 is <tr>\n",
      "<td>1</td>\n",
      "<td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td>\n",
      "<td>300 kg</td>\n",
      "</tr>\n",
      "row 2 is <tr>\n",
      "<td>2</td>\n",
      "<td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n",
      "<td>94 kg</td>\n",
      "</tr>\n",
      "row 3 is <tr>\n",
      "<td>3</td>\n",
      "<td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a> </td>\n",
      "<td>80 kg</td>\n",
      "</tr>\n",
      "row 0\n",
      "colunm 0 cell <td id=\"flight\">Flight No</td>\n",
      "colunm 1 cell <td>Launch site</td>\n",
      "colunm 2 cell <td>Payload mass</td>\n",
      "row 1\n",
      "colunm 0 cell <td>1</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td>\n",
      "colunm 2 cell <td>300 kg</td>\n",
      "row 2\n",
      "colunm 0 cell <td>2</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n",
      "colunm 2 cell <td>94 kg</td>\n",
      "row 3\n",
      "colunm 0 cell <td>3</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a> </td>\n",
      "colunm 2 cell <td>80 kg</td>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Florida', 'Florida']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "\n",
    "html = \"\"\"<!DOCTYPE html>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td id='flight' >Flight No</td>\n",
    "    <td>Launch site</td> \n",
    "    <td>Payload mass</td>\n",
    "   </tr>\n",
    "  <tr> \n",
    "    <td>1</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
    "    <td>300 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
    "    <td>94 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a> </td>\n",
    "    <td>80 kg</td>\n",
    "  </tr>\n",
    "</table>\"\"\" \n",
    "\n",
    "# Changed 'table' to 'html' to match the variable name where the HTML string is stored\n",
    "table_bs = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "table_rows=table_bs.find_all('tr')\n",
    "table_rows\n",
    "\n",
    "first_row =table_rows[0]\n",
    "first_row\n",
    "\n",
    "print(type(first_row))\n",
    "first_row.td\n",
    "\n",
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i,\"is\",row)\n",
    "\n",
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i)\n",
    "    cells=row.find_all('td')\n",
    "    for j,cell in enumerate(cells):\n",
    "        print('colunm',j,\"cell\",cell)\n",
    "        \n",
    "list_input=table_bs .find_all(name=[\"tr\", \"td\"])\n",
    "list_input\n",
    "\n",
    "table_bs.find_all(id=\"flight\")\n",
    "\n",
    "list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\n",
    "list_input\n",
    "\n",
    "table_bs.find_all(href=True)\n",
    "table_bs.find_all('a', href=False)\n",
    "\n",
    "soup.find_all(id=\"boldest\")\n",
    "\n",
    "table_bs.find_all(string=\"Florida\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c20b1e01-18b4-41e1-9c07-48f137de7e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"rocket\">\n",
       "<tr>\n",
       "<td>Flight No</td>\n",
       "<td>Launch site</td>\n",
       "<td>Payload mass</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>1</td>\n",
       "<td>Florida</td>\n",
       "<td>300 kg</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>2</td>\n",
       "<td>Texas</td>\n",
       "<td>94 kg</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>3</td>\n",
       "<td>Florida </td>\n",
       "<td>80 kg</td>\n",
       "</tr>\n",
       "</table>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import requests  \n",
    "\n",
    "\n",
    "# Define the HTML content directly as a string instead of using %%html magic\n",
    "html = \"\"\"\n",
    "<h3>Rocket Launch </h3>\n",
    "\n",
    "<p>\n",
    "<table class='rocket'>\n",
    "  <tr>\n",
    "    <td>Flight No</td>\n",
    "    <td>Launch site</td> \n",
    "    <td>Payload mass</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Florida</td>\n",
    "    <td>300 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>Texas</td>\n",
    "    <td>94 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>Florida </td>\n",
    "    <td>80 kg</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</p>\n",
    "<p>\n",
    "\n",
    "<h3>Pizza Party  </h3>\n",
    "  \n",
    "    \n",
    "<table class='pizza'>\n",
    "  <tr>\n",
    "    <td>Pizza Place</td>\n",
    "    <td>Orders</td> \n",
    "    <td>Slices </td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <td>Domino's Pizza</td>\n",
    "    <td>10</td>\n",
    "    <td>100</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Little Caesars</td>\n",
    "    <td>12</td>\n",
    "    <td >144 </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Papa John's </td>\n",
    "    <td>15 </td>\n",
    "    <td>165</td>\n",
    "  </tr>\n",
    "\"\"\"\n",
    "# Use the 'html' variable instead of 'two_tables'\n",
    "two_tables_bs = BeautifulSoup(html, 'html.parser')\n",
    "two_tables_bs.find(\"table\")\n",
    "\n",
    "two_tables_bs.find(\"table\",class_='pizza')\n",
    "\n",
    "two_tables_bs.find(\"table\",class_ = 'rocket')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7064cc9a-d065-4636-aa29-ff38cb646dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/reports/threat-intelligence/\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/about\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/?lnk=flathl\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/strategy/?lnk=flathl\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/ibmix?lnk=flathl\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/technology/\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/operations/?lnk=flathl\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/strategic-partnerships\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/employment/?lnk=flatitem\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/impact\n",
      "https://web.archive.org/web/20230224123642/https://research.ibm.com/\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/\n",
      "<img alt=\"Person standing with arms crossed\" aria-describedby=\"bx--image-1\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/0a23e414312bcb6f/08196d0e04260ae5_cropped.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/0a23e414312bcb6f/08196d0e04260ae5_cropped.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"Team members at work in a conference room\" aria-describedby=\"bx--image-2\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/06655c075aa3aa29/CaitOppermann_2019_12_06_IBMGarage_DSC3304.jpg.global.m_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/06655c075aa3aa29/CaitOppermann_2019_12_06_IBMGarage_DSC3304.jpg.global.m_16x9.jpg\n",
      "<img alt=\"Coworkers looking at laptops\" aria-describedby=\"bx--image-3\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/08f951353c2707b8/052022_CaitOppermann_InsideIBM_London_2945_03.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/08f951353c2707b8/052022_CaitOppermann_InsideIBM_London_2945_03.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"Cloud developer with red sweater coding at desk\" aria-describedby=\"bx--image-4\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/064e0139f5a3aa5e/0500002_Lowell_LI_100119.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/064e0139f5a3aa5e/0500002_Lowell_LI_100119.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"Aerial view of automated conveyer belt and machinery at work\" aria-describedby=\"bx--image-5\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/0795cae91a25156f/conveyorrobottopview.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/0795cae91a25156f/conveyorrobottopview.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"Overhead view of partners collaborating on design with laptops and coffee\" aria-describedby=\"bx--image-6\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/06dfa9ccdba4ec79/1f417900-9042-44d1-9c219a854bbb62ea.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/06dfa9ccdba4ec79/1f417900-9042-44d1-9c219a854bbb62ea.jpg.global.sr_16x9.jpg\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import requests  \n",
    "\n",
    "#We use get to download the contents of the webpage \n",
    "#in text format and store in a variable called data:\n",
    "\n",
    "url = \"https://web.archive.org/web/20230224123642/https://www.ibm.com/us-en/\"\n",
    "\n",
    "data  = requests.get(url).text \n",
    "soup = BeautifulSoup(data,\"html.parser\") \n",
    "\n",
    "#get link from a web page\n",
    "\n",
    "for link in soup.find_all(\"a\", href = True):\n",
    "    print(link.get(\"href\"))\n",
    "\n",
    "#get picture from a web page\n",
    "for img in soup.find_all(\"img\"):\n",
    "    print(img)\n",
    "    print(img.get(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "364c7708-6975-4f28-963b-8a80c094b922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name--->None\n",
      "lightsalmon--->#FFA07A\n",
      "salmon--->#FA8072\n",
      "darksalmon--->#E9967A\n",
      "lightcoral--->#F08080\n",
      "coral--->#FF7F50\n",
      "tomato--->#FF6347\n",
      "orangered--->#FF4500\n",
      "gold--->#FFD700\n",
      "orange--->#FFA500\n",
      "darkorange--->#FF8C00\n",
      "lightyellow--->#FFFFE0\n",
      "lemonchiffon--->#FFFACD\n",
      "papayawhip--->#FFEFD5\n",
      "moccasin--->#FFE4B5\n",
      "peachpuff--->#FFDAB9\n",
      "palegoldenrod--->#EEE8AA\n",
      "khaki--->#F0E68C\n",
      "darkkhaki--->#BDB76B\n",
      "yellow--->#FFFF00\n",
      "lawngreen--->#7CFC00\n",
      "chartreuse--->#7FFF00\n",
      "limegreen--->#32CD32\n",
      "lime--->#00FF00\n",
      "forestgreen--->#228B22\n",
      "green--->#008000\n",
      "powderblue--->#B0E0E6\n",
      "lightblue--->#ADD8E6\n",
      "lightskyblue--->#87CEFA\n",
      "skyblue--->#87CEEB\n",
      "deepskyblue--->#00BFFF\n",
      "lightsteelblue--->#B0C4DE\n",
      "dodgerblue--->#1E90FF\n",
      "Number ------None\n",
      "1------rgb(255,160,122)\n",
      "2------rgb(250,128,114)\n",
      "3------rgb(233,150,122)\n",
      "4------rgb(240,128,128)\n",
      "5------rgb(255,127,80)\n",
      "6------rgb(255,99,71)\n",
      "7------rgb(255,69,0)\n",
      "8------rgb(255,215,0)\n",
      "9------rgb(255,165,0)\n",
      "10------rgb(255,140,0)\n",
      "11------rgb(255,255,224)\n",
      "12------rgb(255,250,205)\n",
      "13------rgb(255,239,213)\n",
      "14------rgb(255,228,181)\n",
      "15------rgb(255,218,185)\n",
      "16------rgb(238,232,170)\n",
      "17------rgb(240,230,140)\n",
      "18------rgb(189,183,107)\n",
      "19------rgb(255,255,0)\n",
      "20------rgb(124,252,0)\n",
      "21------rgb(127,255,0)\n",
      "22------rgb(50,205,50)\n",
      "23------rgb(0.255.0)\n",
      "24------rgb(34,139,34)\n",
      "25------rgb(0,128,0)\n",
      "26------rgb(176,224,230)\n",
      "27------rgb(173,216,230)\n",
      "28------rgb(135,206,250)\n",
      "29------rgb(135,206,235)\n",
      "30------rgb(0,191,255)\n",
      "31------rgb(176,196,222)\n",
      "32------rgb(30,144,255)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import requests  \n",
    "\n",
    "url =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\"\n",
    "\n",
    "data = requests.get(url).text\n",
    "\n",
    "soup = BeautifulSoup(data,\"html.parser\")\n",
    "\n",
    "table = soup.find('table') \n",
    "\n",
    "#Get all rows from the table\n",
    "for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n",
    "    # Get all columns in each row.\n",
    "    cols = row.find_all('td') # in html a column is represented by the tag <td>\n",
    "    if len(cols) > 0:  # Check if cols is not empty\n",
    "        color_name = cols[2].string # store the value in column 3 as color_name\n",
    "        color_code = cols[3].string # store the value in column 4 as color_code\n",
    "        print(\"{}--->{}\".format(color_name,color_code))\n",
    "\n",
    "for row2 in table.find_all(\"tr\"):\n",
    "    cols = row2.find_all('td')\n",
    "    if len(cols) > 0:  # Check if cols is not empty\n",
    "        number = cols[0].string\n",
    "        decimal_code = cols[4].string\n",
    "        print(\"{}------{}\".format(number,decimal_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74d84a27-6d3b-4564-a01d-c5bb8d635df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have: 26 tables\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (km2)</th>\n",
       "      <th>Density (pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5921231</td>\n",
       "      <td>719</td>\n",
       "      <td>8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>165650475</td>\n",
       "      <td>148460</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Palestine[note 3][102]</td>\n",
       "      <td>5223000</td>\n",
       "      <td>6025</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan[note 4]</td>\n",
       "      <td>23580712</td>\n",
       "      <td>35980</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51844834</td>\n",
       "      <td>99720</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>5296814</td>\n",
       "      <td>10400</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>13173730</td>\n",
       "      <td>26338</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>12696478</td>\n",
       "      <td>27830</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9402617</td>\n",
       "      <td>21937</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1389637446</td>\n",
       "      <td>3287263</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                 Country  Population  Area (km2)  Density (pop/km2)\n",
       "0     1               Singapore     5921231         719               8235\n",
       "1     2              Bangladesh   165650475      148460               1116\n",
       "2     3  Palestine[note 3][102]     5223000        6025                867\n",
       "3     4          Taiwan[note 4]    23580712       35980                655\n",
       "4     5             South Korea    51844834       99720                520\n",
       "5     6                 Lebanon     5296814       10400                509\n",
       "6     7                  Rwanda    13173730       26338                500\n",
       "7     8                 Burundi    12696478       27830                456\n",
       "8     9                  Israel     9402617       21937                429\n",
       "9    10                   India  1389637446     3287263                423"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import requests  \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/World_population\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "data  = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(data.text,\"html.parser\")\n",
    "\n",
    "#find all html tables in the web page\n",
    "tables = soup.find_all('table')\n",
    "#we can see how many tables were found by checking the length of the tables list\n",
    "\n",
    "print(f\"We have: {len(tables)} tables\")\n",
    "\n",
    "for index,table in enumerate(tables):\n",
    "    if(\"10 most densely populated countries\" in str(table)):  # Fixed: changed tables to table and added proper indentation\n",
    "        table_index = index  # Added proper indentation for the code block\n",
    "\n",
    "print(table_index)\n",
    "\n",
    "#print(tables[table_index].prettify())\n",
    "\n",
    "population_data = pd.DataFrame(columns=[\"Rank\", \"Country\", \"Population\", \"Area\", \"Density\"])\n",
    "\n",
    "for row in tables[table_index].tbody.find_all(\"tr\"):\n",
    "    col = row.find_all(\"td\")\n",
    "    if col:\n",
    "        rank = col[0].text.strip()\n",
    "        country = col[1].text.strip()\n",
    "        population = col[2].text.strip()\n",
    "        area = col[3].text.strip()\n",
    "        density = col[4].text.strip()\n",
    "\n",
    "        # Create a temporary DataFrame for the new row\n",
    "        new_row = pd.DataFrame([{\"Rank\": rank, \"Country\": country, \"Population\": population, \"Area\": area, \"Density\": density}])\n",
    "\n",
    "        # Use concat \n",
    "        population_data = pd.concat([population_data, new_row], ignore_index=True)\n",
    "\n",
    "population_data\n",
    "\n",
    "pd.read_html(str(tables[5]), flavor='bs4')\n",
    "\n",
    "population_data_read_html = pd.read_html(str(tables[5]), flavor='bs4')[0]\n",
    "\n",
    "population_data_read_html\n",
    "\n",
    "dataframe_list = pd.read_html(data.text, flavor='bs4')\n",
    "len(dataframe_list)\n",
    "dataframe_list[5]\n",
    "\n",
    "heading = soup.find(\"h3\", {\"id\": \"Most_densely_populated_countries\"})\n",
    "\n",
    "# Get the next table after this heading\n",
    "table = heading.find_next(\"table\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.read_html(str(table))[0]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42a4ee-bfcf-45be-a6e0-c969623f26ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
